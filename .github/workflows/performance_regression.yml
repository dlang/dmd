name: Performance Regression Check
on:
  pull_request:
    types: [opened, synchronize, reopened]

jobs:
  benchmark:
    runs-on: ubuntu-latest
    timeout-minutes: 45
    env:
      MODEL: 64
      BENCHMARK_REPO: https://github.com/dlang/phobos
      BENCHMARK_REF: master

    steps:
    - name: Checkout PR code
      uses: actions/checkout@v4
      with:
        path: pr-dmd

    - name: Checkout master code
      uses: actions/checkout@v4
      with:
        repository: dlang/dmd
        ref: master
        path: master-dmd

    - name: Setup D compiler
      uses: dlang-community/setup-dlang@v1.3.0
      with:
        compiler: dmd-latest

    - name: Build PR compiler
      working-directory: ./pr-dmd
      run: |
        make -j$(nproc) MODEL=$MODEL HOST_DMD=$DC
        mkdir -p generated/linux/release/$MODEL

    - name: Build master compiler
      working-directory: ./master-dmd
      run: |
        make -j$(nproc) MODEL=$MODEL HOST_DMD=$DC
        mkdir -p generated/linux/release/$MODEL

    - name: Compare compiler binaries
      id: diff_check
      run: |
        pr_compiler="./pr-dmd/generated/linux/release/$MODEL/dmd"
        master_compiler="./master-dmd/generated/linux/release/$MODEL/dmd"

        if diff -q "$pr_compiler" "$master_compiler" >/dev/null; then
          echo "DIFF_RESULT=Binaries are identical" >> $GITHUB_OUTPUT
        else
          echo "DIFF_RESULT=Binaries differ" >> $GITHUB_OUTPUT
          diff -u "$pr_compiler" "$master_compiler" || true
        fi

    - name: Checkout benchmark project
      uses: actions/checkout@v4
      with:
        repository: dlang/phobos
        ref: ${{ env.BENCHMARK_REF }}
        path: benchmark-phobos

    - name: Install hyperfine
      run: sudo apt-get install -y hyperfine jq

    - name: Warmup build cache
      working-directory: ./benchmark-phobos
      run: |
        ../pr-dmd/generated/linux/release/$MODEL/dmd -i=std -c -unittest -version=StdUnittest -preview=dip1000 std/package.d || true
        rm -f *.o

    - name: Run benchmarks
      working-directory: ./benchmark-phobos
      run: |
        hyperfine \
          --warmup 1 \
          --runs 5 \
          --show-output \
          --export-json benchmark_results.json \
          --prepare 'rm -f *.o' \
          "../pr-dmd/generated/linux/release/$MODEL/dmd -i=std -c -unittest -version=StdUnittest -preview=dip1000 std/package.d" \
          "../master-dmd/generated/linux/release/$MODEL/dmd -i=std -c -unittest -version=StdUnittest -preview=dip1000 std/package.d"

    - name: Parse results
      id: results
      run: |
        # Check if benchmark file exists
        if [ ! -f benchmark-phobos/benchmark_results.json ]; then
          echo "Error: benchmark results file not found!"
          exit 1
        fi

        # Extract values with error handling
        pr_time=$(jq -r '.results[0].mean // empty' benchmark-phobos/benchmark_results.json)
        master_time=$(jq -r '.results[1].mean // empty' benchmark-phobos/benchmark_results.json)
        pr_time_var=$(jq -r '.results[0].stddev // empty' benchmark-phobos/benchmark_results.json)
        master_time_var=$(jq -r '.results[1].stddev // empty' benchmark-phobos/benchmark_results.json)
        pr_mem=$(jq -r '.results[0].max_rss // 0' benchmark-phobos/benchmark_results.json)
        master_mem=$(jq -r '.results[1].max_rss // 0' benchmark-phobos/benchmark_results.json)
        pr_mem_var=$(jq -r '.results[0].variance // 0' benchmark-phobos/benchmark_results.json)
        master_mem_var=$(jq -r '.results[1].variance // 0' benchmark-phobos/benchmark_results.json)

        # Calculate metrics with scientific notation handling
        calc() { awk "BEGIN { printf \"%.2f\", $* }"; }

        time_diff=$(calc "$pr_time - $master_time")
        time_pct=$(calc "($pr_time/$master_time - 1) * 100")
        time_sig=$(calc "$time_diff / sqrt($pr_time_var^2 + $master_time_var^2)")

        pr_mem_mb=$(calc "$pr_mem / 1024")
        master_mem_mb=$(calc "$master_mem / 1024")
        mem_diff_mb=$(calc "($pr_mem - $master_mem) / 1024")
        mem_pct=$(calc "($pr_mem/$master_mem - 1) * 100")
        mem_sig=$(calc "($pr_mem - $master_mem) / sqrt($pr_mem_var + $master_mem_var)")

        # Set outputs
        echo "pr_time=$pr_time" >> $GITHUB_OUTPUT
        echo "master_time=$master_time" >> $GITHUB_OUTPUT
        echo "time_diff=$time_diff" >> $GITHUB_OUTPUT
        echo "time_pct=$time_pct" >> $GITHUB_OUTPUT
        echo "time_sig=$time_sig" >> $GITHUB_OUTPUT
        echo "pr_mem=$pr_mem_mb" >> $GITHUB_OUTPUT
        echo "master_mem=$master_mem_mb" >> $GITHUB_OUTPUT
        echo "mem_diff=$mem_diff_mb" >> $GITHUB_OUTPUT
        echo "mem_pct=$mem_pct" >> $GITHUB_OUTPUT
        echo "mem_sig=$mem_sig" >> $GITHUB_OUTPUT

    - name: Create comment
      run: |
        PERFORMANCE_COMMENT=$(cat << EOF
        ### ðŸš€ Performance Benchmark Results

        **Comparison between PR and master branch:**
        | Metric          | PR        | Master    | Difference | Change  | Variance | Ïƒ        |
        |-----------------|-----------|-----------|------------|---------|----------|----------|
        | Time (s)        | ${{ format('%.3f', steps.results.outputs.pr_time) }} | ${{ format('%.3f', steps.results.outputs.master_time) }} | ${{ format('%.3f', steps.results.outputs.time_diff) }} | ${{ format('%.2f', steps.results.outputs.time_pct) }}% | Â±${{ format('%.3f', steps.results.outputs.time_var) }} | Ïƒ=${{ format('%.2f', steps.results.outputs.time_sig) }} |
        | Memory (MB)     | ${{ format('%.2f', steps.results.outputs.pr_mem) }} | ${{ format('%.2f', steps.results.outputs.master_mem) }} | ${{ format('%.2f', steps.results.outputs.mem_diff) }} | ${{ format('%.2f', steps.results.outputs.mem_pct) }}% | Â±${{ format('%.0f', steps.results.outputs.mem_var) }} | Ïƒ=${{ format('%.2f', steps.results.outputs.mem_sig) }} |

        **Statistical Significance:**
        - Time: Ïƒ-score of ${{ format('%.2f', steps.results.outputs.time_sig) }} (|Ïƒ| > 2 is significant)
        - Memory: Ïƒ-score of ${{ format('%.2f', steps.results.outputs.mem_sig) }} (|Ïƒ| > 2 is significant)

        **Executable Comparison:**
        ${{ steps.diff_check.outputs.DIFF_RESULT }}

        **Details:**
        - Benchmark project: Phobos@${{ env.BENCHMARK_REF }}
        - 5 runs averaged using [hyperfine](https://github.com/sharkdp/hyperfine)
        - Clean build between runs
        - Variance calculated using pooled standard deviation
        EOF
        )
        echo "$PERFORMANCE_COMMENT" > performance_comment.md

    - name: Post comment
      uses: actions/github-script@v6
      with:
        github-token: ${{ secrets.GITHUB_TOKEN }}
        script: |
          const fs = require('fs');
          const comment = fs.readFileSync('performance_comment.md', 'utf8');
          const { data: comments } = await github.rest.issues.listComments({
            owner: context.repo.owner,
            repo: context.repo.repo,
            issue_number: context.issue.number,
          });

          const existingComment = comments.find(c => c.body.includes('ðŸš€ Performance Benchmark Results'));

          if (existingComment) {
            await github.rest.issues.updateComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              comment_id: existingComment.id,
              body: comment,
            });
          } else {
            await github.rest.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
              body: comment,
            });
          }
